{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pyarrow.parquet as pq # Used to read the data\n",
    "import os \n",
    "import numpy as np\n",
    "from keras.layers import * # Keras is the most friendly Neural Network library, this Kernel use a lot of layers classes\n",
    "from keras.models import Model\n",
    "from tqdm import tqdm # Processing time measurement\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras import backend as K # The backend give us access to tensorflow operations and allow us to create the Attention class\n",
    "from keras import optimizers # Allow us to access the Adam class to modify some parameters\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold # Used to use Kfold to train our model\n",
    "from keras.callbacks import * # This object helps the model to train in a smarter way, avoiding overfitting\n",
    "from kit.attention import Attention\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "from kit.utils import mcc_k\n",
    "from numba import jit\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import pickle\n",
    "import time\n",
    "from dask import dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "from dask import delayed\n",
    "from dask import compute\n",
    "from multiprocessing import cpu_count\n",
    "from dask.distributed import Client\n",
    "nCores = cpu_count()\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "from kit.genesis import FeatureExtractor, data_prep\n",
    "from kit.utils import gen_name, threshold_search, gen_name_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_hardware():\n",
    "    list_of_gpus = K.tensorflow_backend._get_available_gpus()\n",
    "    no_gpu = len([item for item in list_of_gpus if 'GPU' in item])\n",
    "    if no_gpu > 0:\n",
    "        print('Found {} GPUs.'.format(no_gpu))\n",
    "    else:\n",
    "        print('No GPU found!!')\n",
    "    \n",
    "    print('Found {} CPU cores.'.format(nCores))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    meta_train = pd.read_csv('input/metadata_train.csv')\n",
    "    meta_train = meta_train.set_index(['id_measurement', 'phase'])\n",
    "    df_train= pq.read_pandas('input/train.parquet').to_pandas()\n",
    "    return meta_train, df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "289bc7d1ab8048a60025801b457f8df1d848acbc"
   },
   "outputs": [],
   "source": [
    "def model_one(input_shape, kw):\n",
    "    inp = Input(shape=(input_shape[1], input_shape[2],))\n",
    "    x = Bidirectional(LSTM(kw['hu1'], return_sequences=True))(inp)\n",
    "    x = Dropout(rate = kw['dr1'])(x)\n",
    "    x = Bidirectional(LSTM(kw['hu2'], return_sequences=True))(x)    \n",
    "    x = Attention(input_shape[1])(x)\n",
    "    x = Dense(kw['de1'], activation=\"relu\")(x)\n",
    "    x = Dropout(rate =kw['dr2'])(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    if kw['parallel']:\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        parallel_model = multi_gpu_model(model)\n",
    "        parallel_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[mcc_k])\n",
    "    \n",
    "        return parallel_model\n",
    "    else:\n",
    "        model = Model(inputs=inp, outputs=x)\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[mcc_k])\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_config = {\n",
    "    'time_steps': 300,\n",
    "    'spectrogram': {\n",
    "        'freq_bins': 50\n",
    "    },\n",
    "    'abs_rescale':1,\n",
    "    'stats': {\n",
    "        'mean': 1,\n",
    "        'std': 1,\n",
    "        'std_top': 1,\n",
    "        'std_bot': 1,\n",
    "        'max_range': 1,\n",
    "        'percentiles': [0, 10, 25, 50, 75, 90, 100],\n",
    "        'relative_percentiles': [0, 10, 25, 50, 75, 90, 100]\n",
    "    }\n",
    "}\n",
    "\n",
    "model_config = {'hu1': 128, 'hu2': 64, 'dr1': 0.3, 'dr2':0.4, 'de1':64, 'parallel': False}\n",
    "\n",
    "train_config = {'val_split': 0.2, 'stages_desc': [(500,2)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_base(X, y, tcf, model=model_one, model_config = model_config):\n",
    "    \n",
    "    val_split = tcf['val_split']\n",
    "    stages_desc = tcf['stages_desc']\n",
    "    \n",
    "    \n",
    "    t0 = time.time()\n",
    "    stages = dict.fromkeys([i for i in range(len(stages_desc))])\n",
    "    \n",
    "    K.clear_session()\n",
    "    model = model_one(X.shape, model_config)\n",
    "    model.summary()\n",
    "\n",
    "    for i in range(len(stages_desc)):\n",
    "        stages[i] = {'batch_size':stages_desc[i][0], 'epochs': stages_desc[i][1]}\n",
    "        hist_temp = model.fit(X, y, batch_size = stages_desc[i][0], \n",
    "                              epochs = stages_desc[i][1], \n",
    "                              validation_split = 0.2)\n",
    "        stages[i]['results'] = hist_temp.history\n",
    "\n",
    "\n",
    "    model_results = {'config': model.to_json(),\n",
    "                     'training': stages\n",
    "                    }\n",
    "\n",
    "    best_score = max(model_results['training'][0]['results']['val_mcc_k'])\n",
    "    print('='*100+'\\n'+'='*100)\n",
    "    print('Time elapsed: {} minutes... Best score: {} '.format(round(time.time()-t0, 3)/60.0), best_score)\n",
    "    \n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0205 21:08:53.427182 140386526639936 deprecation.py:506] From /home/adi/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 299, 207)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 299, 256)          344064    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 299, 256)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 299, 128)          164352    \n",
      "_________________________________________________________________\n",
      "attention_1 (Attention)      (None, 128)               427       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 517,164\n",
      "Trainable params: 517,164\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2323 samples, validate on 581 samples\n",
      "Epoch 1/2\n",
      "2323/2323 [==============================] - 14s 6ms/step - loss: 0.4940 - mcc_k: -0.0249 - val_loss: 0.1970 - val_mcc_k: 0.0000e+00\n",
      "Epoch 2/2\n",
      "2323/2323 [==============================] - 11s 5ms/step - loss: 0.2578 - mcc_k: 0.0000e+00 - val_loss: 0.1894 - val_mcc_k: 0.0000e+00\n",
      "====================================================================================================\n",
      "====================================================================================================\n",
      "Best score: 0.0.. time elapsed: 0.47346 minutes...\n"
     ]
    }
   ],
   "source": [
    "out_ = train_model_base(X, y, train_config, model=model_one, model_config = model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hptuner(feature_config, model_config, train_config, \n",
    "            data_hyperparam_list=None, \n",
    "            model_hyperparam_list=None):\n",
    "    \n",
    "    check_hardware()\n",
    "    meta_train, df_train = load_data()\n",
    "    \n",
    "    if (not data_hyperparam_list) and (not model_hyperparam_list):\n",
    "        print('No parameters are being varied.')\n",
    "        return\n",
    "    if not data_hyperparam_list:\n",
    "        data_hyperparam_list = [{'1': 1}]  \n",
    "    if not model_hyperparam_list:\n",
    "        model_hyperparam_list = [{'1': 1}]\n",
    "        \n",
    "\n",
    "    for data_hyperparameter_set in data_hyperparam_list:\n",
    "        feature_config.update(data_hyperparameter_set)\n",
    "        feature_pipe = FeatureExtractor(param_config=feature_config)\n",
    "#         X,y = data_prep(meta_train, df_train, feature_pipe)\n",
    "        X = np.load('datasets/X_train.npy')\n",
    "        y = np.load('datasets/y_train.npy')\n",
    "        print(X.shape, y.shape)\n",
    "        \n",
    "        for hyperparameter_set in model_hyperparam_list:\n",
    "            \n",
    "            model_config.update(hyperparameter_set)\n",
    "            train_config.update(hyperparameter_set)\n",
    "            \n",
    "            t0 = time.time()\n",
    "            out_, elapsed_time = train_model_base(X, y, train_config, \n",
    "                                                  model=model_one, \n",
    "                                                  model_config = model_config)\n",
    "            out_['elapsed_time'] = elapsed_time\n",
    "            out_['model_config'] = model_config\n",
    "            out_['train_config'] = train_config\n",
    "            out_['feature_config'] = feature_config\n",
    "            \n",
    "            with open(gen_name_v2('hpt')+'.pkl','wb') as fp:\n",
    "                pickle.dump(out_, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'stages_desc': [(500, 2)]}, {'stages_desc': [(600, 4)]}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'stages_desc': [[(500,2)], [(600,4)]]}\n",
    "list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 GPUs.\n",
      "Found 16 CPU cores.\n",
      "> <ipython-input-56-ece836c9e5e2>(19)hptuner()\n",
      "-> for data_hyperparameter_set in data_hyperparam_list:\n",
      "(Pdb) q.\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-a14011d7903e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhptuner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_hyperparam_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-56-ece836c9e5e2>\u001b[0m in \u001b[0;36mhptuner\u001b[0;34m(feature_config, model_config, train_config, data_hyperparam_list, model_hyperparam_list)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata_hyperparameter_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_hyperparam_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mfeature_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_hyperparameter_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfeature_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-ece836c9e5e2>\u001b[0m in \u001b[0;36mhptuner\u001b[0;34m(feature_config, model_config, train_config, data_hyperparam_list, model_hyperparam_list)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata_hyperparameter_set\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_hyperparam_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mfeature_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_hyperparameter_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfeature_pipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hptuner(feature_config, model_config, train_config, model_hyperparam_list=list(ParameterGrid(param_grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stages_desc [[(500, 2)], [(600, 4)]]\n",
      "caca [1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "for k,v in param_grid.items():\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
